## 大量热点key同时失效

拆解看来，就是一个一个的缓存击穿

### 解决方法

既然雪崩发生的场景是多个key一起过期，那一个简单的解决方法就是不要让这么多key同时过期

**分散key的过期时间**

将每个key的过期时间给一个某范围内的随机数，这样就能使key分散，一个一个的过期

击穿后的并发量也会分为一部分、一部分的打到数据库上

这是最简单，也是最常见的做法

**分散过期时间带来的问题**

如果业务对时间点的要求高，必须指定时间去更新数据

例如：

某某金融系统需要在每天晚上0点整准时更新生成前一天的所有数据报表，且不允许出现旧数据

**跟大并发秒杀系统很像，考虑怎么做削峰**

1. 如果把请求都放到mq里面，然后再一个接一个地消费mq里面的请求

从系统层面上来说，mq确实把存储面临的压力先扛下来，然后异步消费

但是对于 **读请求** 来说，如果通过mq消息队列依次读取，那么必然会有大量读请求超时，这对于用户的查询体验会带来很大的影响

对于 **写请求** 来说，这样做没问题，用户提交写请求后，只要能保证数据最终写入即可，允许异步的等待，跟读请求不一样，没有强时间要求和保证

2. 让缓存提前更新

比如前一天23：58，59的时候开始提前更新部分数据，避免所有数据全部压到0点

但这样做起始是不准确的，例如58开始提前更新前100记录到第二天的报表里面，那假如59又有人写入刷新了前100里面的某些记录，这样导致提前更新的数据失去了时效性

又比如说，某个用户的数据在58被更新了，但是这个用户在59访问系统时

严格上来说在当天23：59应该得到的是前一天的报表数据。结果此时用户已经拿到了今天的报表数据，然后在00：00用户刷新系统，期望拿到今天的数据时，发现数据仍然没有变化，就可能会认为这个系统在00：00居然没有按时更新（即使已经更新了，但是对于用户来说，他在两天查询到了相同的结果）这个系统的时效性就没有得到保证

3. 从1、2可以看到，仅仅让redis分散过期时间，也会出现问题。根据系统架构设计的一个核心思想：存储永远是系统的瓶颈，即使加大前置服务的复杂度来换取高性能的存储，也是可以接受的

所以第三个思路是：**让前置服务分散key的过期**

例如：

时间一到，大量redis的key失效（0点更新）

在业务层（service）查询redis的时候，随即设置一个短的延迟（例如5~50ms）

这样所有对击穿的请求在service层就被提前分散开来，少量的请求可以先穿透到db，然后回写缓存

其他请求因为存在延迟请求redis的设置，就可以从redis中读出数据了

而短延迟（5~50ms）相对于mq的超时不可用来说，是完全可以接受的































































































