### 网络IO模型

处于操作系统安全的考虑，**进程是无法直接访问IO设备的，只能通过系统调用接口，来协助完成IO请求，而内核会为每个IO设备维护一个BUFFER**

![image-20220304202400107](E:\learning-note\middleware\src\main\java\redis\极客时间\pic\image-20220304202400107.png)

1. 用户进程向内核发起请求
2. 内核从IO设备中获取数据存放到对应的buffer里面（内核态）
3. 内核将buffer中的数据拷贝到用户进程所在的地址空间（用户态）
4. 用户进程获取数据相应到客户端

对于整个请求过程，数据从io设备到buffer需要时间，从buffer复制到用户空间也需要时间

根据这两段时间的等待方式不同，分为以下几种**IO模式**：

1. 阻塞IO（Blocking-IO）BIO
2. 非阻塞IO（Non-Blocking-IO）NIO
3. IO复用
4. 信号驱动IO
5. 异步IO



从客户端（用户进程）的角度来说，需要等待的两点：

1. 发起请求后，等待数据准备（内核从IO设备获取数据放到buffer里面）
2. 从内核中将数据拷贝到用户进程（数据从内核态的buffer里拷贝到用户态的内存空间里）



### 阻塞IO（BIO）

linux中，默认所有socket都是BIO方式，流程如下

![image-20220304204007477](E:\learning-note\middleware\src\main\java\redis\极客时间\pic\image-20220304204007477.png)

比如用户进程调用recv系统调用后，内核开始等待网卡的数据，这就进入了第一个阶段：**等待数据**

对于网络IO来说，一般在请求数据的时候，数据往往还没有准备好，或者之准备好了一部分。这个时候就需要内核等待足够的数据到来。

而对于用户进程来说，一旦发起请求数据的调用后，整个进程都会阻塞在这一步，直到内核将数据全部从内核态拷贝到用户态之后，内核返回recv的函数调用，此时用户进程才会解除阻塞状态，开始处理IO设备的数据

综上所述，BIO的特点就是**在等待IO数据、内核态数据拷贝到用户态**这两个阶段，都是**阻塞的**

**特点**

* 及时返回数据，无延迟（对于用户进程来说有数据立马就能使用，对于发起用户进程调用的客户端，仍然需要延迟等待）

### 非阻塞IO（NIO）

![image-20220304204038540](D:\Users\80261561\AppData\Roaming\Typora\typora-user-images\image-20220304204038540.png)

当用户进程调用recv函数时，系统不会阻塞用户进程，而是立即返回一个ewouldblock的错误。

从用户进程的角度来说，它不需要等待所有数据准备好，可以继续处理接下来的事

每隔一段时间，就继续发送recv调用，一旦内核中的数据准备好了（等待IO数据写入buffer），并且收到了用户进程的recv的调用，内核就可以立马将数据从内核态拷贝到用户态，然后返回

用户进程通常在一个循环里，没过一个时间间隔就尝试发起一次非阻塞recv系统调用，这种方式称为**轮询**

**特点**：

* 在等待数据准备完成的时间里，可以做其他事
* 任务完成的响应延迟增大了，因为每次时间间隔之内，数据都有可能准备好。如果在下一个时间间隔开始前数据就准备好了，这不得不导致用户进程仍然要继续等待一个时间间隔。导致系统的吞吐量降低

### IO复用

select和epoll可以监听多个网络连接，可以参考回顾下[epoll的实现方式](E:\learning-note\middleware\src\main\java\redis\面试场景\Redis单线程还是多线程\epoll.md)

当用户进程发起一次select调用后，仍然会被阻塞。于BIO不同的事，此时的select监听的任何一个连接有数据准备好之后，就会唤醒用户进程调用read操作，将数据从内核态拷贝到用户态

![image-20220304204622375](E:\learning-note\middleware\src\main\java\redis\极客时间\pic\image-20220304204622375.png)

和BIO差别不大，甚直还多了一次select的回调。

如果连接数不多的话，使用IO多路复用的性能甚直还比不上单纯的多线程+线程内BIO

IO多路复用的优势：**可以监听和处理多个连接**

**特点**：

* IO多路复用的场景下：用户线程是被**select、epoll**等系统调用阻塞的，而没有阻塞在真正的IO调用，如**IO设备写数据到buffer、内核态数据拷贝到用户态**等过程当中
* **系统开销小**，不用创建额外的线程或者进程，就可以处理多个连接



总的来说，无论是BIO、NIO还是IO复用，从整个IO过程来看，他们都是**顺序执行**的，而且都是**主动等待，且主动检查内核数据的状态**，可以归纳为**同步模型**，即数据不返回就不做其他事儿

### 异步IO

当用户进程发起aio_read系统调用之后，无论内核的数据是否准备好，都会立即返回，然后用户进程就可以做其他事

直到IO设备将数据写入buffer当中，内核将数据从内核态复制到用户态之后，**由内核向用户进程发起通知**，在IO的两个阶段（IO设备准备数据，内核数据复制到用户数据），用户进程都是非阻塞的（在做其他事，等待内核通知）

![image-20220304210741869](E:\learning-note\middleware\src\main\java\redis\极客时间\pic\image-20220304210741869.png)

异步非阻塞IO模型就一定完美吗？

考虑如下场景：

进程提交任务A到后台异步执行，然后开始处理任务B。结果B还没做完，任务A就已经完成并返回了。

如果任务A是一个紧急的事件，需要尽快被响应。那么要么使用中断丢弃做到一半的任务B，要么就慢悠悠的保存B的中间状态，然后切换到A。

但是无论怎么切换，都是需要时间的，这势必降低A的响应速度。



如果任务B也不可丢弃，那么会采用队列的形式，将任务A放到队列里面。等待任务B完成后，再从队列中取出任务A的处理结果。

这必然会增加任务A的响应时间，对于实时系统或者低延迟系统，宁愿采用阻塞方式等待结果返回后立即响应，也比非阻塞返回后还得等当前手上的工作完成才能响应好

